# -*- coding: utf-8 -*-
"""CC25-CF019_Klasifikasi-Gambar-Mata-Terbuka-atau-Mata-Tertutup-v2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1DYH3Of2XucnjsrmkELGWfw54ZtQo7YvG

# Capstone Project Klasifikasi Gambar Mata Terbuka atau Mata Tertutup
- **Nama:** WatchIn
- **Group ID:** CC25-CF019

## Import Semua Packages/Library yang Digunakan
"""

!pip install tensorflowjs

import os
import shutil
import numpy as np
import pandas as pd
import cv2
from tqdm import tqdm
import matplotlib.pyplot as plt
import tensorflow as tf
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from keras.models import Sequential, load_model
from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout, BatchNormalization
from keras.callbacks import EarlyStopping, ReduceLROnPlateau
import tensorflowjs as tfjs
from sklearn.metrics import accuracy_score
from tensorflow.keras.preprocessing import image

import warnings
warnings.filterwarnings('ignore')

"""## Data Preparation

### Data Loading
"""

from google.colab import files
files.upload()

!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

#!/bin/bash
!kaggle datasets download -d serenaraju/yawn-eye-dataset-new

!unzip yawn-eye-dataset-new.zip

# Lokasi dataset asli dan target baru
source_dir = 'dataset_new'
target_dir = 'dataset_combined'

# Buat struktur folder baru
for phase in ['train', 'test']:
    os.makedirs(os.path.join(target_dir, phase, 'closed'), exist_ok=True)
    os.makedirs(os.path.join(target_dir, phase, 'opened'), exist_ok=True)

    # Gabungkan Closed dan yawn ke closed folder
    for cls in ['Closed', 'yawn']:
        src_path = os.path.join(source_dir, phase, cls)
        dst_path = os.path.join(target_dir, phase, 'closed')
        for file in os.listdir(src_path):
            shutil.copy(os.path.join(src_path, file), os.path.join(dst_path, file))

    # Gabungkan Open dan no_yawn ke opened
    for cls in ['Open', 'no_yawn']:
        src_path = os.path.join(source_dir, phase, cls)
        dst_path = os.path.join(target_dir, phase, 'opened')
        for file in os.listdir(src_path):
            shutil.copy(os.path.join(src_path, file), os.path.join(dst_path, file))

print("Penggabungan selesai. Data disimpan ke folder 'dataset_combined'")

def load_images(directory):
    images = []
    labels = []

    for category in os.listdir(directory):
        category_path = os.path.join(directory, category)
        for filename in tqdm(os.listdir(category_path), desc=f"Loading {category}"):
            image_path = os.path.join(category_path, filename)
            image = cv2.imread(image_path)
            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
            image = cv2.resize(image, (224, 224))
            images.append(image)
            labels.append(category)

    images = np.array(images, dtype='float32')
    return images, labels

data_dir = 'dataset_combined/train/'
X, y = load_images(data_dir)

data_dir_test = 'dataset_combined/test/'
X_test, y_test = load_images(data_dir_test)

def tampilkan_contoh_gambar_tertentu(images, labels, kelas_unik, jumlah_per_kelas=3):
    plt.figure(figsize=(jumlah_per_kelas * 3, len(kelas_unik) * 3))

    for idx, kelas in enumerate(kelas_unik):
        indeks_kelas = [i for i, label in enumerate(labels) if label == kelas]

        contoh_indeks = [
            indeks_kelas[0],
            indeks_kelas[len(indeks_kelas) // 2],
            indeks_kelas[-1]
        ]

        for j, indeks in enumerate(contoh_indeks):
            i = idx * jumlah_per_kelas + j
            plt.subplot(len(kelas_unik), jumlah_per_kelas, i + 1)
            plt.imshow(images[indeks].astype('uint8'))
            plt.title(f"{kelas}")
            plt.axis('off')

    plt.tight_layout()
    plt.show()

kelas_unik = sorted(set(y))
tampilkan_contoh_gambar_tertentu(X, y, kelas_unik, jumlah_per_kelas=3)

distribusi = pd.Series(y).value_counts()

print("Distribusi jumlah gambar per kelas:")
print(distribusi)

"""### Split Dataset"""

X = X / 255.0

encoder = LabelEncoder()
y = encoder.fit_transform(y)

X_test = X_test / 255.0

encoder = LabelEncoder()
y_test = encoder.fit_transform(y_test)

X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1, stratify=y, random_state=42)

"""## Modelling"""

model = Sequential()

model.add(Conv2D(filters=16,kernel_size=3,activation='relu',input_shape=(224,224,3)))
model.add(MaxPooling2D(pool_size=2))

model.add(Conv2D(filters=32,kernel_size=3,activation='relu',padding='same'))
model.add(MaxPooling2D(pool_size=2))
model.add(BatchNormalization())
model.add(Dropout(0.5))

model.add(Conv2D(filters=64,kernel_size=3,activation='relu'))
model.add(MaxPooling2D(pool_size=2))
model.add(BatchNormalization())
model.add(Dropout(0.2))

model.add(Conv2D(filters=128,kernel_size=3,activation='relu'))
model.add(MaxPooling2D(pool_size=2))
model.add(BatchNormalization())
model.add(Dropout(0.25))

model.add(Flatten())

model.add(Dense(units=128,activation='relu'))
model.add(BatchNormalization())
model.add(Dropout(0.25))

model.add(Dense(units=1,activation='sigmoid'))

warnings.filterwarnings('ignore')

model.summary()

model.compile(optimizer='adam',
              loss='binary_crossentropy',
              metrics=['accuracy'])

early_stop = EarlyStopping(monitor='val_accuracy',patience=20,mode='max',verbose=1,restore_best_weights=True)
reduce_lr = ReduceLROnPlateau(monitor='val_accuracy',patience=5,mode='max',verbose=1,factor=0.1,min_lr=0.001)

history = model.fit(x=X_train,
            y=y_train,
            epochs=30,
            batch_size=32,
            validation_data=(X_val,y_val),
            callbacks=[early_stop,reduce_lr])

warnings.filterwarnings('ignore')

"""## Evaluasi dan Visualisasi"""

acc = history.history['accuracy']
val_acc = history.history['val_accuracy']
loss = history.history['loss']
val_loss = history.history['val_loss']

epochs = range(len(acc))

plt.plot(epochs, acc, 'r')
plt.plot(epochs, val_acc, 'b')
plt.title('Training and Validation Accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'val'], loc='upper left')
plt.show()

plt.plot(epochs, loss, 'r')
plt.plot(epochs, val_loss, 'b')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'val'], loc='upper left')
plt.title('Training and Validaion Loss')
plt.show()

train_loss, train_acc = model.evaluate(X_train, y_train, verbose=0)
val_loss, val_acc = model.evaluate(X_val, y_val, verbose=0)

print(f"Akurasi Train: {train_acc:.4f}")
print(f"Akurasi Validation: {val_acc:.4f}")

test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)
print(f"Test Accuracy: {test_acc:.4f}")

"""## Konversi Model"""

save_path = 'saved_model/'
tf.saved_model.save(model, save_path)

!tensorflowjs_converter \
    --input_format=tf_saved_model \
    /content/saved_model/ \
    /content/model_tfjs

!zip -r saved_model.zip /content/saved_model/

!zip -r /content/model_tfjs.zip /content/model_tfjs/

"""## Inference"""

# Memuat model dari folder SavedModel
loaded_model = tf.saved_model.load('/content/saved_model')
print("Model berhasil dimuat!")

# Mengunggah gambar (misalnya 'image.jpg')
img = image.load_img('/content/Opened-1.jpg', target_size=(224, 224))

# Preprocessing gambar menjadi array
img_array = image.img_to_array(img)
img_array = np.expand_dims(img_array, axis=0)  # Menambah dimensi batch
img_array /= 255.0  # Normalisasi jika diperlukan

# Menampilkan gambar
plt.imshow(img_array[0])  # Mengakses elemen pertama dari batch
plt.title("Gambar yang Diproses")
plt.axis("off")  # Menghilangkan sumbu
plt.show()

print("Data siap untuk inference!")

# Daftar label kelas (urutannya harus sesuai dengan saat pelatihan model)
class_names = ['Opened', 'Closed']

# Melakukan inference
predictions = model.predict(img_array)

# Menampilkan hasil prediksi (probabilitas)
print("Hasil prediksi:", predictions)

# Mengambil indeks kelas dengan probabilitas tertinggi
predicted_class = np.argmax(predictions, axis=1)[0]

# Mengonversi indeks menjadi nama kelas
predicted_class_name = class_names[predicted_class]

# Menampilkan nama kelas
print("Kelas prediksi:", predicted_class_name)